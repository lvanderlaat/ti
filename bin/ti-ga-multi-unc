#!/usr/bin/env python


"""
"""


# Python Standard Library
import argparse
import os

from itertools import repeat
from multiprocessing import Pool

# Other dependencies
import numpy as np
import pandas as pd
import ti
import xarray as xr

from pymoo.algorithms.soo.nonconvex.ga import GA
from pymoo.operators.crossover.sbx import SBX
from pymoo.operators.mutation.pm import PM
from pymoo.termination import get_termination
from scipy.ndimage import gaussian_filter
from pymoo.optimize import minimize


# Local files

__author__ = 'Leonardo van der Laat'
__email__ = 'laat@umich.edu'


def parse_args():
    parser = argparse.ArgumentParser(
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    parser.add_argument('configfile', help='Configuration file path')
    parser.add_argument('station', help='Station')
    return parser.parse_args()


def invert(i, problem, algorithm, termination):
    # Optimize
    result = minimize(
        problem, algorithm, termination,
        seed=i,  # Change the seed every time to get some randomness
        save_history=False, verbose=False,
    )

    if result.X is None:
        return None
    else:
        return problem.var_to_dict(result.X)


def main():
    # Load configuration
    args = parse_args()
    c = ti.config.read(args.configfile)

    # Output
    folderpath = ti.utils.create_folder(
        c.io.output_dir, f'GA_MULTI_{args.station}', c.io.overwrite
    )
    ti.utils.write_conf(c, folderpath)

    ti.parameters.write_latex(c, folderpath)

    # Load channels
    channels = pd.read_csv(c.source.channels_csv, comment='/')
    channels = channels[channels.station == args.station]
    channels.to_csv(os.path.join(folderpath, 'channels.csv'), index=False)

    # Load observations
    obs = xr.open_dataarray(os.path.join(c.optimize.obs_folder, 'data.nc'))

    # Filter depending to channels csv file
    obs = obs.where(obs.station.isin(channels.station), drop=True)
    obs = obs.sel(
        station=args.station,
        t=slice(c.source.starttime, c.source.endtime)
    )

    # Algorithm
    algorithm = GA(
        pop_size=c.moo.pop_size,
        n_offsprings=c.moo.n_offsprings,
        crossover=SBX(**c.moo.sbx),
        mutation=PM(**c.moo.pm),
        eliminate_duplicate=c.moo.eliminate_duplicate
    )

    # Termination criteria
    termination = get_termination('n_gen', c.moo.n_gen)

    # Model parameters
    param = dict(c.model)
    keys = [key for key, value in param.items() if type(value) is list]
    param['xr'] = channels.x.tolist()
    param['yr'] = channels.y.tolist()
    param['zr'] = channels.z.tolist()

    f = obs.f.values
    delta = c.multi.delta
    sigma = c.multi.sigma

    import time

    Sxx_syn, opts_out = [], []
    for i, Sx_obs in enumerate(obs.transpose('t', 'f').data):
        print(i)

        t0 = time.time()

        df_max = ti.multichromatic.get_peaks(Sx_obs, param['n'])

        # Set number of resonators
        param['n'] = len(df_max)

        # Set range of natural frequency
        fnat = f[df_max.idx]
        fnat_range = [fnat - delta, fnat + delta]

        # Smooth observation
        Sx_obs = gaussian_filter(Sx_obs, sigma=sigma)

        # Initialize problem
        problem = ti.multichromatic.Problem(
            Sx_obs=Sx_obs,
            f=f,
            param=param,
            keys=keys,
            fnat_range=fnat_range,
            sigma=sigma,
        )

        args_parallel = zip(
            range(c.uncertainty.n),
            repeat(problem),
            repeat(algorithm),
            repeat(termination),
        )

        with Pool(c.max_workers) as pool:
            _opts = pool.starmap(invert, args_parallel)

        # take care the case where no convergence was attained.
        opts = [opt for opt in _opts if opt is not None]

        if len(opts) < 1:
            Sx_syn = np.empty(f.size)
            Sx_syn[:] = np.nan
            Sxx_syn.append(Sx_syn)
            continue

        # Get mean for unfixed parameters
        _param = param.copy()
        for key in keys:
            _param[key] = np.mean([opt[key] for opt in opts], axis=0)

        # Synthetize spectrogram with mean parameters
        Sx_syn, _fnat = ti.model_multi.synthetize(**_param)
        Sx_syn = Sx_syn[0]
        Sxx_syn.append(Sx_syn)

        # Format the output parameters
        for j, opt in enumerate(opts):
            for k in range(opt['n']):
                opt_out = dict(
                    datetime=obs.t.values[i], fnat=fnat[k], iteration=j
                )
                for key in opt.keys():
                    if isinstance(opt[key], np.ndarray):
                        if len(opt[key]) == opt['n']:
                            opt_out[key] = opt[key][k]
                        else:
                            opt_out[key] = opt[key][0]
                    else:
                        opt_out[key] = opt[key]
                opts_out.append(opt_out)

        t1 = time.time()
        exec_time = t1 - t0
        print(f'Time to process {c.uncertainty.n}: {exec_time:.0f} s')

    # Write output spectrogram and parameters
    df = pd.DataFrame(opts_out)
    df.to_csv(os.path.join(folderpath, 'params.csv'))

    Sxx_syn = np.array(Sxx_syn)

    syn = xr.DataArray(
        Sxx_syn,
        dims=('t', 'f'),
        coords=dict(t=obs.t, f=obs.f)
    )
    syn.to_netcdf(os.path.join(folderpath, 'data.nc'))

    # Final plot
    Sxx_obs = gaussian_filter(obs, sigma=c.multi.sigma)
    Sxx_syn = gaussian_filter(Sxx_syn, sigma=c.multi.sigma)

    fig = ti.plot.obs_vs_synth(
        obs.t.to_numpy(), obs.f.to_numpy(), Sxx_obs.T, Sxx_syn.T
    )
    fig.savefig(os.path.join(folderpath, 'comparison.png'), dpi=250)
    return


if __name__ == '__main__':
    main()
